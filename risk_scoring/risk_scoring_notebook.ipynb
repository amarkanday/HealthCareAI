{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Health Insurance Member Risk Scoring Model - Interactive Analysis\n",
    "\n",
    "Data Disclaimer:\n",
    "All data, statistics, and examples in this script are synthetic and created for \n",
    "educational demonstration purposes only. No real member data, proprietary healthcare \n",
    "information, or actual insurance company data are used.\n",
    "\n",
    "This script demonstrates a comprehensive machine learning approach to predicting \n",
    "healthcare cost and utilization risk among health insurance members.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37d987",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "1. IMPORT LIBRARIES AND SETUP\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configuration for reproducible results\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e708100",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"Health Insurance Member Risk Scoring Model\")\n",
    "print(\"Synthetic Data Only - No Real Member Information\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd39bac",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "2. DATA GENERATION FUNCTION\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f3ed9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_member_data(n_members=10000):\n",
    "    \"\"\"Generate synthetic member data with realistic healthcare patterns\"\"\"\n",
    "    \n",
    "    print(f\"Generating synthetic data for {n_members} members...\")\n",
    "    \n",
    "    # Demographics\n",
    "    ages = np.random.normal(45, 18, n_members)\n",
    "    ages = np.clip(ages, 18, 85).astype(int)\n",
    "    \n",
    "    genders = np.random.choice(['M', 'F'], n_members, p=[0.48, 0.52])\n",
    "    \n",
    "    # Geographic regions\n",
    "    regions = np.random.choice(['Northeast', 'Southeast', 'Midwest', 'West'], \n",
    "                              n_members, p=[0.25, 0.28, 0.22, 0.25])\n",
    "    \n",
    "    # Plan types\n",
    "    plan_types = np.random.choice(['HMO', 'PPO', 'EPO', 'POS'], \n",
    "                                 n_members, p=[0.35, 0.40, 0.15, 0.10])\n",
    "    \n",
    "    # Employment status affects utilization\n",
    "    employment_status = np.random.choice(['Employed', 'Retired', 'Disabled', 'Unemployed'],\n",
    "                                       n_members, p=[0.65, 0.20, 0.08, 0.07])\n",
    "    \n",
    "    # Previous year medical costs (strong predictor)\n",
    "    prev_costs = np.random.lognormal(7.5, 1.8, n_members)\n",
    "    prev_costs = np.clip(prev_costs, 0, 150000)\n",
    "    \n",
    "    # Chronic conditions (age-dependent probabilities)\n",
    "    diabetes_prob = np.where(ages < 40, 0.05, np.where(ages < 65, 0.12, 0.25))\n",
    "    has_diabetes = np.random.binomial(1, diabetes_prob)\n",
    "    \n",
    "    hypertension_prob = np.where(ages < 40, 0.08, np.where(ages < 65, 0.25, 0.45))\n",
    "    has_hypertension = np.random.binomial(1, hypertension_prob)\n",
    "    \n",
    "    heart_disease_prob = np.where(ages < 50, 0.02, np.where(ages < 70, 0.08, 0.18))\n",
    "    has_heart_disease = np.random.binomial(1, heart_disease_prob)\n",
    "    \n",
    "    copd_prob = np.where(ages < 50, 0.01, np.where(ages < 70, 0.05, 0.12))\n",
    "    has_copd = np.random.binomial(1, copd_prob)\n",
    "    \n",
    "    mental_health_prob = np.where(ages < 30, 0.15, np.where(ages < 60, 0.12, 0.08))\n",
    "    has_mental_health = np.random.binomial(1, mental_health_prob)\n",
    "    \n",
    "    # Healthcare utilization metrics\n",
    "    primary_care_visits = np.random.poisson(3, n_members)\n",
    "    specialist_visits = np.random.poisson(2 + has_diabetes + has_heart_disease + has_copd, n_members)\n",
    "    er_visits = np.random.poisson(0.5 + 0.3 * has_diabetes + 0.4 * has_heart_disease, n_members)\n",
    "    \n",
    "    # Pharmacy utilization\n",
    "    rx_count = np.random.poisson(5 + 3 * has_diabetes + 2 * has_hypertension + \n",
    "                                2 * has_heart_disease + has_mental_health, n_members)\n",
    "    \n",
    "    # BMI (affects risk)\n",
    "    bmi = np.random.normal(28, 6, n_members)\n",
    "    bmi = np.clip(bmi, 16, 50)\n",
    "    \n",
    "    # Smoking status\n",
    "    smoking_prob = np.where(ages < 30, 0.18, np.where(ages < 65, 0.15, 0.08))\n",
    "    is_smoker = np.random.binomial(1, smoking_prob)\n",
    "    \n",
    "    # Create target variable (high risk)\n",
    "    risk_score = (\n",
    "        0.3 * (prev_costs / 10000) +\n",
    "        0.2 * (ages / 100) +\n",
    "        0.15 * has_diabetes +\n",
    "        0.12 * has_heart_disease +\n",
    "        0.08 * has_copd +\n",
    "        0.05 * (er_visits / 5) +\n",
    "        0.05 * is_smoker +\n",
    "        0.03 * (bmi - 25) / 10 +\n",
    "        0.02 * (rx_count / 10)\n",
    "    )\n",
    "    \n",
    "    # Add noise and create binary target\n",
    "    risk_score += np.random.normal(0, 0.1, n_members)\n",
    "    high_risk = (risk_score > np.percentile(risk_score, 85)).astype(int)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'member_id': range(1, n_members + 1),\n",
    "        'age': ages,\n",
    "        'gender': genders,\n",
    "        'region': regions,\n",
    "        'plan_type': plan_types,\n",
    "        'employment_status': employment_status,\n",
    "        'prev_year_costs': prev_costs,\n",
    "        'has_diabetes': has_diabetes,\n",
    "        'has_hypertension': has_hypertension,\n",
    "        'has_heart_disease': has_heart_disease,\n",
    "        'has_copd': has_copd,\n",
    "        'has_mental_health': has_mental_health,\n",
    "        'primary_care_visits': primary_care_visits,\n",
    "        'specialist_visits': specialist_visits,\n",
    "        'er_visits': er_visits,\n",
    "        'rx_count': rx_count,\n",
    "        'bmi': bmi,\n",
    "        'is_smoker': is_smoker,\n",
    "        'high_risk': high_risk\n",
    "    })\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592840ec",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "3. RISK SCORE CALCULATOR FUNCTION\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9ede3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_risk_score(member_data, model, scaler, feature_columns):\n",
    "    \"\"\"\n",
    "    Calculate risk score for new member data\n",
    "    \n",
    "    Parameters:\n",
    "    member_data: dict with member information\n",
    "    model: trained model object\n",
    "    scaler: fitted StandardScaler object\n",
    "    feature_columns: list of feature column names\n",
    "    \n",
    "    Returns:\n",
    "    risk_score: probability of being high-risk (0-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    member_df = pd.DataFrame([member_data])\n",
    "    \n",
    "    # Ensure all required features are present\n",
    "    for col in feature_columns:\n",
    "        if col not in member_df.columns:\n",
    "            member_df[col] = 0  # Default value\n",
    "    \n",
    "    # Select and order features\n",
    "    X_member = member_df[feature_columns]\n",
    "    \n",
    "    # Scale if using logistic regression\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        X_member_scaled = scaler.transform(X_member)\n",
    "        risk_prob = model.predict_proba(X_member_scaled)[0, 1]\n",
    "    else:\n",
    "        risk_prob = model.predict_proba(X_member)[0, 1]\n",
    "    \n",
    "    return risk_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d85ba",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "4. MAIN ANALYSIS EXECUTION\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca8ffe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Execute the complete risk scoring analysis\"\"\"\n",
    "    \n",
    "    # Generate the dataset\n",
    "    df = generate_member_data(10000)\n",
    "\n",
    "    print(f\"Dataset created with {len(df)} members\")\n",
    "    print(f\"High-risk members: {df['high_risk'].sum()} ({df['high_risk'].mean()*100:.1f}%)\")\n",
    "    print(\"\\nDataset Overview:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # =============================================================================\n",
    "    # 5. DATA PREPROCESSING\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA PREPROCESSING AND FEATURE ENGINEERING\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Check for missing values\n",
    "    print(\"Missing values per column:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Feature engineering\n",
    "    df['age_groups'] = pd.cut(df['age'], bins=[0, 30, 50, 65, 100], \n",
    "                             labels=['18-30', '31-50', '51-65', '65+'])\n",
    "\n",
    "    df['bmi_category'] = pd.cut(df['bmi'], bins=[0, 18.5, 25, 30, 50],\n",
    "                               labels=['Underweight', 'Normal', 'Overweight', 'Obese'])\n",
    "\n",
    "    df['total_chronic_conditions'] = (df['has_diabetes'] + df['has_hypertension'] + \n",
    "                                     df['has_heart_disease'] + df['has_copd'] + \n",
    "                                     df['has_mental_health'])\n",
    "\n",
    "    df['total_visits'] = df['primary_care_visits'] + df['specialist_visits'] + df['er_visits']\n",
    "\n",
    "    df['cost_per_visit'] = df['prev_year_costs'] / (df['total_visits'] + 1)\n",
    "\n",
    "    print(\"Feature engineering completed!\")\n",
    "    print(f\"Total features available: {len(df.columns)}\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # 6. EXPLORATORY DATA ANALYSIS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Risk distribution analysis\n",
    "    print(\"Risk Distribution by Demographics:\")\n",
    "    print(f\"Age groups:\")\n",
    "    age_risk = df.groupby('age_groups')['high_risk'].agg(['count', 'mean'])\n",
    "    print(age_risk)\n",
    "    \n",
    "    print(f\"\\nChronic conditions impact:\")\n",
    "    chronic_risk = df.groupby('total_chronic_conditions')['high_risk'].agg(['count', 'mean'])\n",
    "    print(chronic_risk)\n",
    "\n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # Age distribution by risk\n",
    "    axes[0,0].hist([df[df['high_risk']==0]['age'], df[df['high_risk']==1]['age']], \n",
    "                   bins=20, alpha=0.7, label=['Low Risk', 'High Risk'])\n",
    "    axes[0,0].set_title('Age Distribution by Risk Level')\n",
    "    axes[0,0].set_xlabel('Age')\n",
    "    axes[0,0].set_ylabel('Count')\n",
    "    axes[0,0].legend()\n",
    "\n",
    "    # Previous costs by risk\n",
    "    low_risk_costs = df[df['high_risk']==0]['prev_year_costs']\n",
    "    high_risk_costs = df[df['high_risk']==1]['prev_year_costs']\n",
    "    axes[0,1].boxplot([low_risk_costs, high_risk_costs], labels=['Low Risk', 'High Risk'])\n",
    "    axes[0,1].set_title('Previous Year Costs by Risk Level')\n",
    "    axes[0,1].set_ylabel('Previous Year Costs ($)')\n",
    "\n",
    "    # Chronic conditions impact\n",
    "    axes[1,0].bar(chronic_risk.index, chronic_risk['mean'])\n",
    "    axes[1,0].set_title('Risk Rate by Number of Chronic Conditions')\n",
    "    axes[1,0].set_xlabel('Number of Chronic Conditions')\n",
    "    axes[1,0].set_ylabel('High Risk Rate')\n",
    "\n",
    "    # ER visits impact\n",
    "    er_risk = df.groupby('er_visits')['high_risk'].mean()\n",
    "    axes[1,1].bar(er_risk.index[:8], er_risk.values[:8])  # Show first 8 values\n",
    "    axes[1,1].set_title('Risk Rate by ER Visits')\n",
    "    axes[1,1].set_xlabel('Number of ER Visits')\n",
    "    axes[1,1].set_ylabel('High Risk Rate')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('risk_analysis_plots.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # =============================================================================\n",
    "    # 7. MODEL DEVELOPMENT\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL DEVELOPMENT\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    le_gender = LabelEncoder()\n",
    "    le_region = LabelEncoder()\n",
    "    le_plan = LabelEncoder()\n",
    "    le_employment = LabelEncoder()\n",
    "\n",
    "    df['gender_encoded'] = le_gender.fit_transform(df['gender'])\n",
    "    df['region_encoded'] = le_region.fit_transform(df['region'])\n",
    "    df['plan_type_encoded'] = le_plan.fit_transform(df['plan_type'])\n",
    "    df['employment_encoded'] = le_employment.fit_transform(df['employment_status'])\n",
    "\n",
    "    # Select features for modeling\n",
    "    feature_columns = [\n",
    "        'age', 'gender_encoded', 'region_encoded', 'plan_type_encoded', 'employment_encoded',\n",
    "        'prev_year_costs', 'has_diabetes', 'has_hypertension', 'has_heart_disease', \n",
    "        'has_copd', 'has_mental_health', 'primary_care_visits', 'specialist_visits',\n",
    "        'er_visits', 'rx_count', 'bmi', 'is_smoker', 'total_chronic_conditions',\n",
    "        'total_visits', 'cost_per_visit'\n",
    "    ]\n",
    "\n",
    "    X = df[feature_columns]\n",
    "    y = df['high_risk']\n",
    "\n",
    "    print(f\"Features selected: {len(feature_columns)}\")\n",
    "    print(\"Feature list:\", feature_columns)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                        random_state=42, stratify=y)\n",
    "\n",
    "    print(f\"\\nTraining set: {len(X_train)} samples\")\n",
    "    print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100)\n",
    "    }\n",
    "\n",
    "    # Train and evaluate models\n",
    "    model_results = {}\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        if name == 'Logistic Regression':\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        auc_score = roc_auc_score(y_test, y_prob)\n",
    "        accuracy = (y_pred == y_test).mean()\n",
    "        \n",
    "        # Cross-validation\n",
    "        if name == 'Logistic Regression':\n",
    "            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "        else:\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "        \n",
    "        model_results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc_score,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'predictions': y_pred,\n",
    "            'probabilities': y_prob,\n",
    "            'model': model\n",
    "        }\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"AUC: {auc_score:.3f}\")\n",
    "        print(f\"CV AUC: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})\")\n",
    "        \n",
    "        if auc_score > best_score:\n",
    "            best_score = auc_score\n",
    "            best_model = name\n",
    "\n",
    "    print(f\"\\nBest performing model: {best_model} (AUC: {best_score:.3f})\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # 8. MODEL EVALUATION\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"DETAILED MODEL EVALUATION - {best_model}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    best_model_obj = model_results[best_model]['model']\n",
    "    best_predictions = model_results[best_model]['predictions']\n",
    "    best_probabilities = model_results[best_model]['probabilities']\n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, best_predictions))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, best_predictions)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Low Risk', 'High Risk'],\n",
    "                yticklabels=['Low Risk', 'High Risk'])\n",
    "    plt.title(f'Confusion Matrix - {best_model}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importance (for tree-based models)\n",
    "    if best_model in ['Random Forest', 'Gradient Boosting']:\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': feature_columns,\n",
    "            'importance': best_model_obj.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop 10 Most Important Features:\")\n",
    "        for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):\n",
    "            print(f\"{i+1:2d}. {row['feature']:25s} {row['importance']:.4f}\")\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        top_features = feature_importance.head(10)\n",
    "        plt.barh(range(len(top_features)), top_features['importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title('Top 10 Feature Importance')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    # =============================================================================\n",
    "    # 9. BUSINESS IMPACT ANALYSIS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUSINESS IMPACT ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Risk score distribution\n",
    "    risk_scores = best_probabilities * 100  # Convert to 0-100 scale\n",
    "\n",
    "    print(f\"Risk Score Distribution:\")\n",
    "    print(f\"Mean risk score: {risk_scores.mean():.1f}\")\n",
    "    print(f\"Median risk score: {np.median(risk_scores):.1f}\")\n",
    "    print(f\"90th percentile: {np.percentile(risk_scores, 90):.1f}\")\n",
    "    print(f\"95th percentile: {np.percentile(risk_scores, 95):.1f}\")\n",
    "\n",
    "    # Plot risk score distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(risk_scores, bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Risk Score (%)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Risk Scores')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(risk_scores)\n",
    "    plt.ylabel('Risk Score (%)')\n",
    "    plt.title('Risk Score Box Plot')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('risk_score_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Analyze high-risk predictions\n",
    "    high_risk_threshold = 0.7  # 70% probability threshold\n",
    "    high_risk_predicted = best_probabilities >= high_risk_threshold\n",
    "\n",
    "    print(f\"\\nMembers flagged as high-risk (â‰¥70% probability): {high_risk_predicted.sum()}\")\n",
    "    print(f\"Percentage of total population: {high_risk_predicted.mean()*100:.1f}%\")\n",
    "\n",
    "    # True positive rate among flagged members\n",
    "    if high_risk_predicted.sum() > 0:\n",
    "        precision_high_risk = y_test[high_risk_predicted].mean()\n",
    "        print(f\"Precision for high-risk flag: {precision_high_risk:.3f}\")\n",
    "\n",
    "    # Cost concentration analysis\n",
    "    test_data = df.iloc[X_test.index].copy()\n",
    "    test_data['risk_score'] = risk_scores\n",
    "    test_data['predicted_high_risk'] = high_risk_predicted\n",
    "\n",
    "    # Top 10% highest risk members\n",
    "    top_10_percent = test_data.nlargest(int(len(test_data) * 0.1), 'risk_score')\n",
    "    print(f\"\\nTop 10% highest risk members characteristics:\")\n",
    "    print(f\"Average age: {top_10_percent['age'].mean():.1f}\")\n",
    "    print(f\"Diabetes rate: {top_10_percent['has_diabetes'].mean()*100:.1f}%\")\n",
    "    print(f\"Heart disease rate: {top_10_percent['has_heart_disease'].mean()*100:.1f}%\")\n",
    "    print(f\"Average ER visits: {top_10_percent['er_visits'].mean():.1f}\")\n",
    "    print(f\"Average previous costs: ${top_10_percent['prev_year_costs'].mean():.0f}\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # 10. EXAMPLE RISK SCORE CALCULATION\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE RISK SCORE CALCULATION\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    example_member = {\n",
    "        'age': 58,\n",
    "        'gender_encoded': 1,  # Female\n",
    "        'region_encoded': 2,  # Midwest\n",
    "        'plan_type_encoded': 1,  # PPO\n",
    "        'employment_encoded': 0,  # Employed\n",
    "        'prev_year_costs': 8500,\n",
    "        'has_diabetes': 1,\n",
    "        'has_hypertension': 1,\n",
    "        'has_heart_disease': 0,\n",
    "        'has_copd': 0,\n",
    "        'has_mental_health': 0,\n",
    "        'primary_care_visits': 4,\n",
    "        'specialist_visits': 6,\n",
    "        'er_visits': 1,\n",
    "        'rx_count': 8,\n",
    "        'bmi': 32.5,\n",
    "        'is_smoker': 0,\n",
    "        'total_chronic_conditions': 2,\n",
    "        'total_visits': 11,\n",
    "        'cost_per_visit': 8500/11\n",
    "    }\n",
    "\n",
    "    example_risk = calculate_risk_score(\n",
    "        example_member, \n",
    "        best_model_obj, \n",
    "        scaler if best_model == 'Logistic Regression' else None, \n",
    "        feature_columns\n",
    "    )\n",
    "\n",
    "    print(f\"Example member profile:\")\n",
    "    print(f\"- Age: 58, Female, Midwest, PPO plan\")\n",
    "    print(f\"- Has diabetes and hypertension\")\n",
    "    print(f\"- Previous year costs: $8,500\")\n",
    "    print(f\"- BMI: 32.5 (obese)\")\n",
    "    print(f\"- Total visits: 11\")\n",
    "    print(f\"\\nCalculated Risk Score: {example_risk:.1%}\")\n",
    "    print(f\"Risk Category: {'HIGH' if example_risk >= 0.7 else 'MODERATE' if example_risk >= 0.3 else 'LOW'}\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # 11. RECOMMENDATIONS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL DEPLOYMENT RECOMMENDATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"1. Use 70% probability threshold for high-risk intervention\")\n",
    "    print(\"2. Focus care management on members with multiple chronic conditions\")\n",
    "    print(\"3. Prioritize members with previous high costs and recent ER visits\")\n",
    "    print(\"4. Consider preventive outreach for members scoring 50-70%\")\n",
    "    print(\"5. Monthly model retraining recommended with updated claims data\")\n",
    "    print(\"\\nBusiness Value:\")\n",
    "    print(\"- Early identification of high-risk members before costly episodes\")\n",
    "    print(\"- Efficient resource allocation for care management\")\n",
    "    print(\"- Potential 10-15% reduction in high-risk member costs\")\n",
    "    print(\"- Better health outcomes through proactive care\")\n",
    "\n",
    "    print(f\"\\nModel development completed successfully!\")\n",
    "    print(f\"Final model ready for deployment: {best_model}\")\n",
    "    \n",
    "    return best_model_obj, scaler, feature_columns, model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d22f5a",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "12. SCRIPT EXECUTION\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e506e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run the complete analysis\n",
    "    model, scaler, features, results = main()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"All plots have been saved as PNG files.\")\n",
    "    print(\"Model objects are available for further use.\") "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
